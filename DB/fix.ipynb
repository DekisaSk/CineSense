{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee7e0079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been rewritten as: merged_cast_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"merged_cast.csv\"\n",
    "output_file = \"merged_cast_fixed.csv\"\n",
    "\n",
    "with open(input_file, \"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    # Use QUOTE_ALL to force quoting of every field\n",
    "    writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "    for row in reader:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"CSV file has been rewritten as:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e858c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV fixed; output written to tv_shows_temp_fixed_null.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"tv_shows_temp_fixed.csv\"\n",
    "output_file = \"tv_shows_temp_fixed_null.csv\"\n",
    "\n",
    "with open(input_file, \"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    for row in reader:\n",
    "        # Replace empty first_air_date with \\N\n",
    "        if row.get(\"first_air_date\", \"\").strip() == \"\":\n",
    "            row[\"first_air_date\"] = r\"\\N\"\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"CSV fixed; output written to\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57725b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in persons.csv: 3553674\n",
      "Total in tv_persons.csv: 934137\n",
      "Filtered tv_persons.csv rows: 374544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs ensuring person_id is read as a string.\n",
    "persons_df = pd.read_csv(\"merged_cast.csv\", dtype={'person_id': str})\n",
    "tv_persons_df = pd.read_csv(\"tv_persons_temp.csv\", dtype={'person_id': str})\n",
    "\n",
    "# Strip any extra whitespace in the person_id columns.\n",
    "persons_df[\"person_id\"] = persons_df[\"person_id\"].str.strip()\n",
    "tv_persons_df[\"person_id\"] = tv_persons_df[\"person_id\"].str.strip()\n",
    "\n",
    "# Debug prints: check the number of rows before filtering.\n",
    "print(\"Total in persons.csv:\", len(persons_df))\n",
    "print(\"Total in tv_persons.csv:\", len(tv_persons_df))\n",
    "\n",
    "# Filter tv_persons_df: keep only rows where person_id is not in persons_df.\n",
    "filtered_tv_persons_df = tv_persons_df[~tv_persons_df[\"person_id\"].isin(persons_df[\"person_id\"])]\n",
    "\n",
    "# Debug print: check the number of rows after filtering.\n",
    "print(\"Filtered tv_persons.csv rows:\", len(filtered_tv_persons_df))\n",
    "\n",
    "# Save the filtered DataFrame.\n",
    "filtered_tv_persons_df.to_csv(\"tv_persons_filtered.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ff019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7b22bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file written to: merged_cast.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(file1, file2, output_file, key_columns=None):\n",
    "    \"\"\"\n",
    "    Merge two CSV files and remove duplicate rows.\n",
    "    \n",
    "    Parameters:\n",
    "    - file1: Path to the first CSV file.\n",
    "    - file2: Path to the second CSV file.\n",
    "    - output_file: Path for the output merged CSV file.\n",
    "    - key_columns: List of columns to use as keys for identifying duplicates.\n",
    "                   If None, duplicates are dropped based on all columns.\n",
    "    \"\"\"\n",
    "    # Read the CSV files\n",
    "    df1 = pd.read_csv(file1, dtype=str)\n",
    "    df2 = pd.read_csv(file2, dtype=str)\n",
    "    \n",
    "    # Concatenate the DataFrames\n",
    "    merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    if key_columns:\n",
    "        merged_df = merged_df.drop_duplicates(subset=key_columns)\n",
    "    else:\n",
    "        merged_df = merged_df.drop_duplicates()\n",
    "    \n",
    "    # Write the merged DataFrame to CSV\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged file written to: {output_file}\")\n",
    "\n",
    "\n",
    "# Merge cast_temp.csv and tv_cast_temp.csv\n",
    "merge_csv_files(\"cast_temp.csv\", \"tv_cast_temp.csv\", \"merged_cast.csv\", key_columns=[\"credit_id\", \"person_id\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
